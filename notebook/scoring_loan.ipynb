{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc104bcf",
   "metadata": {},
   "source": [
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=5368709120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9865d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Reset memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb34f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import joblib\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b922fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from scipy.stats import spearmanr\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import pickle\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d56ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0917621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/td/implement_scoring_loan/notebook/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5164fc",
   "metadata": {},
   "source": [
    "# Imbalanced Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "426cf482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, Count=105059, Percentage=34.165%\n",
      "Class=1, Count=202448, Percentage=65.835%\n"
     ]
    }
   ],
   "source": [
    "# summarize the class distribution\n",
    "from collections import Counter\n",
    "\n",
    "target = df.values[:,2]\n",
    "counter = Counter(target)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "163c12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['TARGET'],axis=1)\n",
    "y=df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3ac6ce4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'fit_resample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-20d84c2a344c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# transform the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'fit_resample'"
     ]
    }
   ],
   "source": [
    "# Séparation des données en données d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=39)\n",
    "\n",
    "# Équilibrage des données en utilisant SMOTE\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_train_resampled, y_train_resampled= pipeline.fit_resample(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff85bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled.value_counts()/len(y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b28a34",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c97f10",
   "metadata": {},
   "source": [
    "Before we can improve our model, we need a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17890727",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(random_state=39) \n",
    "#establishing random_state for reproducibility\n",
    "clf_dummy.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = clf_dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11056d05",
   "metadata": {},
   "source": [
    "## MLFLOW UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c34fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mlflow(model):\n",
    "    # Track params and metrics \n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.set_tag(\"model_name\", name)\n",
    "        mlflow.log_param(\"Colums\", paramgrid)\n",
    "        # Save model to artifacts\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', models_[model_]['model'])])\n",
    "        gscv = GridSearchCV(pipe, param_grid=models_[model_]['params'], cv=cv,scoring='accuracy')\n",
    "        gscv.fit(X_train_resampled,y_train_resampled)\n",
    "        mlflow.sklearn.log_model(gscv.best_estimator_, name)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred), 4)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c179e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score metier\n",
    "def score_metier(y_test,y_pred):\n",
    "    cost_fn = 10 ### coût d’un FN est dix fois supérieur au coût d’un FP\n",
    "    cost_fp = 1\n",
    "    # Matrice de confusion pour calculer le nombre de FN et de FP ## Voir proba avec seuil\n",
    "    confusion_matrix = np.array([[np.sum((y_pred == 0) & (y_test == 0)), np.sum((y_pred == 1) & (y_test == 0))],\n",
    "                                 [np.sum((y_pred == 0) & (y_test == 1)), np.sum((y_pred == 1) & (y_test == 1))]])\n",
    "    score_metier = cost_fp * confusion_matrix[0,1] + cost_fn * confusion_matrix[1,0]\n",
    "    return score_metier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dc1f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical and categorical pipelines\n",
    "\n",
    "preprocessor=PowerTransformer(method='yeo-johnson',standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f536ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_log_reg = {'model__penalty': ['l1', 'l2'],\n",
    "    'model__C': np.logspace(-4, 4, 20),\n",
    "    'model__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "param_Xgboost = {\n",
    "    'model__n_estimators': [50,100],\n",
    "    'model__max_depth': [3, 4],\n",
    "    'model__learning_rate': [0.01, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24060d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de classifieurs \n",
    "models_ = { 'Logistic Regression':{'model':LogisticRegression(),'params':param_log_reg},\n",
    "            'Xgboost':{'model': XGBClassifier(), 'params':param_Xgboost}\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20237116",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d90a8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/20 18:10:57 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '55af88ee03ee43f0b67d55e97b4838d6', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaire de classifieurs \n",
    "models_ = { 'Logistic Regression':{'model':LogisticRegression(),'params':param_log_reg},\n",
    "            'Xgboost':{'model': XGBClassifier(), 'params':param_Xgboost}\n",
    "              }\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "for model_ in models_.keys():\n",
    "    experiment_name = model_\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', models_[model_]['model'])])\n",
    "    gscv = GridSearchCV(pipe, param_grid=models_[model_]['params'], cv=cv,scoring='accuracy')\n",
    "    gscv.fit(X_train_resampled,y_train_resampled)\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_):\n",
    "        mlflow.sklearn.log_model(gscv.best_estimator_, model_)\n",
    "        \n",
    "        # Evaluate the model on the test data\n",
    "\n",
    "        probabilities = pipe.predict_proba(X_test)\n",
    "        #Score metier\n",
    "        threshold = 0.7\n",
    "        y_pred = np.where(probabilities[:, 1] >= threshold, 1, 0)\n",
    "\n",
    "        cost_fn = 10  # coût d’un FN est dix fois supérieur au coût d’un FP\n",
    "        cost_fp = 1\n",
    "        # Matrice de confusion pour calculer le nombre de FN et de FP ## Voir proba avec seuil\n",
    "        confusion_matrix = np.array([[np.sum((y_pred == 0) & (y_test == 0)), np.sum((y_pred == 1) & (y_test == 0))],\n",
    "                                     [np.sum((y_pred == 0) & (y_test == 1)), np.sum((y_pred == 1) & (y_test == 1))]])\n",
    "        score_metier = cost_fp * confusion_matrix[0,1] + cost_fn * confusion_matrix[1,0]\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(pipe, \"model\")\n",
    "\n",
    "        # score_metier as metrics\n",
    "        accuracy = round(accuracy_score(y_test, y_pred), 4)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"score_metier\", score_metier)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Erase experiment\n",
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "# client = MlflowClient()\n",
    "# experiments = client.search_experiments(\"DummyClassifier\")\n",
    "# for experiment in experiments:\n",
    "#     client.delete_experiment(experiment.experiment_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0819d",
   "metadata": {},
   "source": [
    "## STREAMLIT AND FASTAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9402ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the selected model\n",
    "\n",
    "model_saved=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model for fastapi\n",
    "\n",
    "joblib.dump(model_saved, './scoring_loan.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba94bb",
   "metadata": {},
   "source": [
    "### Unit Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my_module import score_metier\n",
    "import unittest\n",
    "class TestScoreMetier(unittest.TestCase):\n",
    "\n",
    "    def test_score_metier(self):\n",
    "        y_test = np.array([0, 1, 0, 1, 0, 1])\n",
    "        y_pred = np.array([0, 1, 1, 1, 0, 0])\n",
    "        expected_score = 20 # Calculé manuellement pour les entrées ci-dessus\n",
    "        self.assertEqual(score_metier(y_test, y_pred), expected_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd87efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/td/implement_scoring_loan/notebook/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dff6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
